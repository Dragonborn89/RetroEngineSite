<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>RetroEngine â€” Dev Log 1: From First Light to First Frame</title>
<link rel="stylesheet" href="../style.css">
</head>
<body>

<header>
  <h1>Dev Log 1: From First Light to First Frame</h1>
  <nav>
    <a href="/">Home</a>
    <a href="/devlog/">Dev Log</a>
    <a href="/about/">About</a>
  </nav>
</header>

<main>
  <section>
    <h2> Getting Started</h2>
    <p>Having never setup a game engine or render pipeline, my first goal was setting up a self-contained Direct3D 12/Win 32 application in cpp. Its not much to look at, but this was the "birth" of my engine. A simple gpu-driven output of vertex and pixel shaders compiling ðŸŽ‰! This would be the core everything else would build upon.</p>

    <img src="../assets/images/devlog01_01.jpg" alt="Engine Birth">

  </section>

  <section>
    <h2>Part I â€” The Birth of the Beam</h2>
    <p>RetroEngine started as a Direct3D 12 prototype with one goal: to simulate a cathode-ray tube not as a post-process effect, but as a physically modeled display system.</p>

    <p>When you look closely at a real CRT screen, you donâ€™t see pixels....you see phosphors. Tiny dots or stripes of red, green, and blue light that glow when struck by the electron beam. Different CRTs used different arrangements:<p>

    <ul>
      <li><strong>Shadow Mask:</strong> circular RGB triads like curved consumer televisions</li>
      <li><strong>Aperture Grille:</strong> vertical RGB stripes used in Trinitron and broadcast PVM monitors</li>
    </ul>

    <p>To begin building my physically-based CRT renderer, I needed to reproduce these layouts procedurally on the GPU. Every subpixel, every mask pattern, rendered in real time. The results can be seen in this image. The top is a reference diagram of real CRT masks. The bottom is the same pattern being generated by my engine. I taught the GPU how to draw those microscopic red, green, and blue structures that sit beneath every pixel:</p>

    <img src="../assets/images/devlog01_02.jpg" alt="Mask Patterns">


    <p>This is the foundation of RetroEngine...not a post-process filter, but a true simulation of how a CRT displays an image. The first milestone was creating the world a CRT actually lives in the phosphor mask.</p> 

    <p>Each pattern is generated procedurally in the shader (no textures, no lookup images). Every dot and stripe comes from math. This was where the renderer first felt alive: real-time phosphor geometry instead of static color blocks.</p>

    <video controls loop autoplay muted>
    <source src="../assets/videos/TestRendering01.mp4" type="video/mp4">
    </video>
    
  </section>

  <section>
  <h2>Part II â€” Teaching Light to Move</h2>

  <p>When a CRT draws an image, it doesnâ€™t show all the pixels at once. A focused electron beam scans across the screen, lighting up phosphors that glow and fade over time. The next milestone was teaching RetroEngine to do the same.</p>

  <p>The renderer now simulates a moving scanline that excites each phosphor with brightness-dependent decay. Every pixel lives and fades on its own schedule, just like glass and light would behave in the real world.</p>

  <ul>
    <li><strong>Beam behavior and afterglow:</strong> the renderer now models a traveling raster sweep that excites phosphors with realistic decay.</li>
    <li><strong>Real texture input:</strong> instead of test bars, RetroEngine now renders any image through the CRT pipeline.</li>
    <li><strong>Physically-based blending:</strong> a Gaussian beam profile with nonlinear response gives each subpixel its own soft halo.</li>
    <li><strong>Performance:</strong> running stable at 60 FPS with full control over mask type, pitch, scanline depth, and decay timing.</li>
  </ul>

  <p>For the first time, the renderer showed motion. Pixels glowed, trailed, and faded naturally, even though it was just a static image. It wasnâ€™t just drawing color anymoreâ€”it was drawing <em>light</em>.</p>

  <h3>The Comparison</h3>
  <p>Below is the original test image I fed into the renderer, followed by the same frame viewed through the beam and phosphor simulation stage. It needs help, but every scanline and RGB triad is driven by the same math that powered real displays.</p>

  <img src="../assets/images/devlog01_03.png" alt="Original test image used for CRT rendering">

  <video controls autoplay muted loop>
    <source src="../assets/videos/Texturerenderoutput.mp4" type="video/mp4">
  </video>
</section>

  <section>
  <h2>Part III â€” Persistence, Optics, and the Feeling of Glass</h2>

  <p>Once the beam simulation came alive, the next step was to make it feel physical. Real CRTs donâ€™t just draw a new image each frame; they blend light over time. A phosphor doesnâ€™t stop glowing the instant the beam passesâ€”it fades, mixes, and diffuses through glass. I rebuilt the renderer around that idea.</p>

  <p>The new pipeline runs in two temporal passes that model how energy accumulates on a screen:</p>

  <ul>
    <li><strong>Pass A â€” Persistence Builder:</strong> merges new beam emission with decayed light from previous frames stored in HDR ping-pong buffers. This is what gives the display its sense of inertiaâ€”light that remembers.</li>
    <li><strong>Pass B â€” Composite & Output:</strong> applies optical shaping: gamma curves, phosphor weighting, and a faint lens diffusion that mimics how light scatters inside a glass faceplate.</li>
  </ul>

  <p>After tuning the response, the image finally behaved like something behind glass:</p>

  <ul>
    <li>Dual-zone gamma shaping deepened shadows without crushing midtones</li>
    <li>Phosphor weighting balanced warmth between the green and red channels</li>
    <li>Soft low-frequency diffusion added the kind of analog bloom you only get from glass</li>
  </ul>

  <p>For the first time, RetroEngine felt less like a digital renderer and more like a physical device. Deep, film-like blacks replaced milky grays. Color started to carry energy instead of just hue. Motion left traces of light that looked alive. Here is a slideshow of some test textures I ran through it:</p>

  <div class="slideshow">
  <div class="slide fade">
    <img src="../assets/images/devlog01_04a.jpg" alt="CRT persistence test A">
  </div>
  <div class="slide fade">
    <img src="../assets/images/devlog01_04b.jpg" alt="CRT persistence test B">
  </div>
  <div class="slide fade">
    <img src="../assets/images/devlog01_04c.jpg" alt="CRT persistence test C">
  </div>
  <div class="slide fade">
    <img src="../assets/images/devlog01_04d.jpg" alt="CRT persistence test D">
  </div>
</div>

</section>

  <section>
    <h2>Part IV â€” The Mystery of the Muted Greens</h2>
    <p>During a refactor, I finally found the bug that made every scene look flat. Textures were loaded as sRGB but sampled as linear UNORM, so the shader was reading gamma-encoded values. The CRT pass then applied its own shaping, and the GPU encoded again â€” effectively double darkening the image.</p>

    <p>Fixing it meant rebuilding the color pipeline:</p>
    <ul>
      <li>Textures flagged as sRGB so the GPU linearizes automatically</li>
      <li>CRT pass operates entirely in linear HDR (R16G16B16A16_FLOAT)</li>
      <li>Swapchain performs a single sRGB encode at output</li>
    </ul>

    <p>Once fixed, the change was immediate. Greens came alive. Blues regained depth. The glow math behaved like real energy. The renderer finally felt unified from input to glass.</p>

    <img src="../assets/images/devlog01_05a.jpg" alt="Original test image used for CRT rendering">
    <img src="../assets/images/devlog01_05b.jpg" alt="Original test image used for CRT rendering">
    <img src="../assets/images/devlog01_05c.jpg" alt="Original test image used for CRT rendering">
  </section>

  <section>
    <h2>Part V â€” The Cube Lives</h2>
    <p>With the CRT system stable, I gave it something real to draw: a simple 3D cube. I added a test scene with a camera, transform matrices, and a mesh loader. That cube became the first object rendered through the full beam and persistence pipeline.</p>

    <ul>
      <li>A geometry pass renders to an HDR buffer</li>
      <li>The buffer feeds into the CRT system as its signal</li>
      <li>The beam simulation, phosphor decay, and optical bloom process it in real time</li>
    </ul>

    <p>It was finally time to fire it up for the first time and see the 3D world getting passed into the renderer:</p>

    <video controls loop autoplay muted>
    <source src="../assets/videos/First3DRender01.mp4" type="video/mp4">
    </video>

    <p>Watching that cube flicker through the simulated raster proved it. RetroEngine isnâ€™t a filter. Itâ€™s a viewport model â€” a virtual CRT capable of showing real worlds.</p>

    
  </section>

  <section class="summary">
    <h2>Closing Thoughts</h2>
    <p>This first stage was about one thing: light. Understanding it, shaping it, and making it behave the way it did on glass. The CRT system is alive now. Next up is giving that light a world to illuminate, moving beyond a simple test scene and expanding the engine's capability to support fully constructed worlds.</p>

    <video controls loop autoplay muted>
    <source src="../assets/videos/landingpage_demo.mp4" type="video/mp4">
    </video>
  </section>

</main>

<footer>
  <p>Â© 2025 RetroEngine</p>
</footer>

</body>
</html>
